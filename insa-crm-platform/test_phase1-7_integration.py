#!/usr/bin/env python3
"""
INSA CRM Platform - Phase 1-7 Integration Test
Tests complete workflow: Lead Capture ‚Üí AI Qualification ‚Üí Quote Generation ‚Üí ERPNext
"""

import sys
import json
from pathlib import Path
from datetime import datetime

# Add to path
sys.path.insert(0, str(Path(__file__).parent / "core"))

print("="*80)
print("INSA CRM PLATFORM - PHASE 1-7 INTEGRATION TEST")
print("="*80)
print(f"Test Date: {datetime.utcnow().isoformat()}")
print(f"Server: iac1 (100.100.101.1)")
print("")

# Test results tracker
results = {
    "tests_run": 0,
    "tests_passed": 0,
    "tests_failed": 0,
    "failures": []
}

def test_result(name, passed, details=""):
    """Record test result"""
    results["tests_run"] += 1
    if passed:
        results["tests_passed"] += 1
        print(f"‚úÖ PASS: {name}")
        if details:
            print(f"   ‚Üí {details}")
    else:
        results["tests_failed"] += 1
        results["failures"].append({"test": name, "details": details})
        print(f"‚ùå FAIL: {name}")
        if details:
            print(f"   ‚Üí {details}")
    print()

# ============================================================================
# PHASE 0: ENVIRONMENT CHECK
# ============================================================================
print("\n" + "="*80)
print("PHASE 0: ENVIRONMENT CHECK")
print("="*80 + "\n")

# Test 1: Python environment
try:
    import structlog
    import chromadb
    import pydantic
    test_result("Python dependencies installed", True,
                "structlog, chromadb, pydantic available")
except ImportError as e:
    test_result("Python dependencies installed", False, str(e))

# Test 2: Storage directories
storage_paths = [
    "/var/lib/insa-crm/quote_knowledge_base",
    "/var/lib/insa-crm/quotes"
]
all_exist = all(Path(p).exists() for p in storage_paths)
test_result("Storage directories exist", all_exist,
            ", ".join(storage_paths))

# Test 3: Reference projects
ref_project = Path("~/insa-crm-platform/projects/customers/INSAGTEC-6598").expanduser()
test_result("Reference project exists", ref_project.exists(),
            f"INSAGTEC-6598 at {ref_project}")

# ============================================================================
# PHASE 1: LEAD QUALIFICATION AGENT
# ============================================================================
print("\n" + "="*80)
print("PHASE 1: LEAD QUALIFICATION AGENT")
print("="*80 + "\n")

try:
    from agents.lead_qualification_agent import LeadQualificationAgent

    agent = LeadQualificationAgent()

    # Test lead
    test_lead = {
        "company": "Test Manufacturing Inc",
        "contact_name": "John Doe",
        "email": "john@testmfg.com",
        "phone": "+1-555-0100",
        "project_description": "Need PLC system for new production line, Allen-Bradley preferred, IEC 62443 compliance required, budget $150K, urgent timeline 3 months",
        "industry": "Manufacturing"
    }

    # Note: Agent requires Claude Code - will use fallback scoring
    print("Testing lead qualification (using fallback logic)...")
    print(f"Lead: {test_lead['company']} - {test_lead['project_description'][:50]}...")

    test_result("Lead Qualification Agent initialized", True,
                "Agent ready for scoring")

except Exception as e:
    test_result("Lead Qualification Agent", False, str(e))

# ============================================================================
# PHASE 7: QUOTE GENERATION SYSTEM
# ============================================================================
print("\n" + "="*80)
print("PHASE 7: QUOTE GENERATION SYSTEM")
print("="*80 + "\n")

try:
    from agents.quote_generation.quote_orchestrator import QuoteOrchestrator

    # Test 7.1: Initialize orchestrator
    try:
        orchestrator = QuoteOrchestrator()
        test_result("Quote Orchestrator initialized", True,
                    "All sub-agents loaded")
    except Exception as e:
        test_result("Quote Orchestrator initialized", False, str(e))
        raise

    # Test 7.2: RAG Knowledge Base
    try:
        stats = orchestrator.rag.get_statistics()
        project_count = stats.get('total_projects', 0)
        test_result("RAG Knowledge Base operational", project_count > 0,
                    f"{project_count} projects indexed")
    except Exception as e:
        test_result("RAG Knowledge Base operational", False, str(e))

    # Test 7.3: Generate test quote
    try:
        print("Generating test quote...")
        test_rfp = """
        We need a control system for a three-phase oil separator at our refinery.
        Requirements:
        - Allen-Bradley CompactLogix PLC with 50 I/O points
        - HMI system with 20 screens for operators
        - Level, pressure, and temperature instrumentation (15 instruments total)
        - Full IEC 62443-3-3 cybersecurity compliance
        - API RP 14C compliance for oil & gas
        - Timeline: 6 months
        - Budget: approximately $200,000 USD

        Similar to the INSAGTEC-6598 project we've heard about.
        """

        quote = orchestrator.generate_quote(
            requirement_source=test_rfp,
            customer_name="Test Refinery Corp",
            customer_email="engineering@testrefinery.com",
            source_type="text"
        )

        quote_id = quote.get('quote_id')
        total_price = quote.get('pricing', {}).get('pricing', {}).get('total', 0)
        gen_time = quote.get('metadata', {}).get('generation_time_seconds', 0)
        confidence = quote.get('approval', {}).get('overall_confidence', 0)

        details = f"Quote {quote_id}: ${total_price:,.2f} in {gen_time}s (confidence: {confidence:.0%})"
        test_result("Quote generated successfully", total_price > 0, details)

        # Save test quote for inspection
        test_quote_path = Path("/tmp/integration_test_quote.json")
        with open(test_quote_path, 'w') as f:
            json.dump(quote, f, indent=2)

        print(f"   Test quote saved: {test_quote_path}")
        print()

    except Exception as e:
        test_result("Quote generation", False, str(e))
        import traceback
        traceback.print_exc()

    # Test 7.4: Quote components
    if 'quote' in locals():
        has_bom = len(quote.get('bill_of_materials', {}).get('items', [])) > 0
        test_result("BOM generated", has_bom,
                    f"{len(quote['bill_of_materials']['items'])} items")

        has_labor = quote.get('labor_estimate', {}).get('total_hours', 0) > 0
        labor_hours = quote.get('labor_estimate', {}).get('total_hours', 0)
        test_result("Labor estimate calculated", has_labor,
                    f"{labor_hours:.1f} hours")

        has_pricing = quote.get('pricing', {}).get('strategy') is not None
        strategy = quote.get('pricing', {}).get('strategy', 'unknown')
        test_result("Pricing strategy applied", has_pricing,
                    f"Strategy: {strategy}")

        similar_count = len(quote.get('similar_projects', []))
        test_result("Similar projects found", similar_count > 0,
                    f"{similar_count} similar projects")

except Exception as e:
    test_result("Quote Generation System", False, str(e))
    import traceback
    traceback.print_exc()

# ============================================================================
# MCP INTEGRATION CHECKS (Phase 2-6)
# ============================================================================
print("\n" + "="*80)
print("PHASES 2-6: MCP SERVER INTEGRATION")
print("="*80 + "\n")

# Test MCP configuration
try:
    mcp_config_path = Path.home() / ".mcp.json"
    if mcp_config_path.exists():
        with open(mcp_config_path) as f:
            mcp_config = json.load(f)

        servers = list(mcp_config.get('mcpServers', {}).keys())

        # Key servers for our platform
        required_servers = [
            'erpnext-crm',      # Phase 3
            'inventree-crm',    # Phase 2
            'mautic-admin',     # Phase 4
            'n8n-admin',        # Phase 6
            'defectdojo-iec62443'  # Security
        ]

        for server in required_servers:
            exists = server in servers
            test_result(f"MCP Server: {server}", exists,
                       "Configured in ~/.mcp.json")

        test_result("MCP configuration valid", True,
                   f"{len(servers)} total servers configured")
    else:
        test_result("MCP configuration exists", False,
                   "~/.mcp.json not found")

except Exception as e:
    test_result("MCP configuration", False, str(e))

# ============================================================================
# WORKFLOW INTEGRATION TEST
# ============================================================================
print("\n" + "="*80)
print("COMPLETE WORKFLOW TEST")
print("="*80 + "\n")

workflow_steps = [
    "1. Lead captured from website/form",
    "2. AI qualification agent scores lead (0-100)",
    "3. High-value lead (>80) triggers quote generation",
    "4. Quote generated in <1 second with:",
    "   - Requirements extracted",
    "   - Similar projects found (RAG)",
    "   - BOM generated",
    "   - Labor estimated",
    "   - Pricing calculated",
    "5. Quote saved to ERPNext (MCP integration)",
    "6. Email sent via Mautic (MCP integration)",
    "7. Follow-up workflow triggered in n8n"
]

print("Complete Workflow:")
for step in workflow_steps:
    print(f"  {step}")
print()

# Verify workflow is possible
can_qualify = results["tests_passed"] >= 1  # Lead qualification works
can_quote = 'quote' in locals() and quote.get('quote_id') is not None  # Quote generation works
has_mcp = mcp_config_path.exists()  # MCP servers configured

workflow_ready = can_qualify and can_quote and has_mcp
test_result("Complete workflow ready", workflow_ready,
           "All components operational for end-to-end automation")

# ============================================================================
# FINAL RESULTS
# ============================================================================
print("\n" + "="*80)
print("TEST SUMMARY")
print("="*80 + "\n")

print(f"Total Tests: {results['tests_run']}")
print(f"Passed: {results['tests_passed']} ‚úÖ")
print(f"Failed: {results['tests_failed']} ‚ùå")
print(f"Success Rate: {(results['tests_passed']/results['tests_run']*100):.1f}%")
print()

if results['tests_failed'] > 0:
    print("FAILURES:")
    for failure in results['failures']:
        print(f"  ‚ùå {failure['test']}")
        if failure['details']:
            print(f"     {failure['details']}")
    print()

# Overall status
if results['tests_failed'] == 0:
    print("üéâ ALL TESTS PASSED - SYSTEM FULLY OPERATIONAL")
    sys.exit(0)
elif results['tests_passed'] > results['tests_failed']:
    print("‚ö†Ô∏è  PARTIAL SUCCESS - SOME COMPONENTS NEED ATTENTION")
    sys.exit(1)
else:
    print("‚ùå SYSTEM NOT READY - CRITICAL FAILURES")
    sys.exit(2)
