# ============================================================================
# Alkhorayef ESP IoT Platform - Environment Configuration Template
# ============================================================================
# Copy this file to .env and update with your actual values
# IMPORTANT: Never commit .env to version control
# ============================================================================

# ----------------------------------------------------------------------------
# Application Settings
# ----------------------------------------------------------------------------
# Environment: development, staging, production
ENVIRONMENT=production

# Flask/FastAPI environment mode
FLASK_ENV=production

# Application timezone (use IANA timezone format)
TZ=UTC

# Python buffering (disable for Docker logs)
PYTHONUNBUFFERED=1

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Structured JSON logging (true for production)
JSON_LOGGING=true

# ----------------------------------------------------------------------------
# API Server Configuration
# ----------------------------------------------------------------------------
# Main API port (FastAPI application)
API_PORT=8000

# ML Service port (if running separately)
ML_SERVICE_PORT=8001

# Number of Gunicorn worker processes (2-4 x CPU cores)
GUNICORN_WORKERS=4

# Worker class (uvicorn.workers.UvicornWorker for ASGI)
GUNICORN_WORKER_CLASS=uvicorn.workers.UvicornWorker

# Request timeout in seconds
GUNICORN_TIMEOUT=120

# Keep-alive connections timeout
GUNICORN_KEEPALIVE=5

# API host binding (0.0.0.0 for all interfaces, 127.0.0.1 for localhost only)
API_HOST=0.0.0.0

# ----------------------------------------------------------------------------
# PostgreSQL Database Configuration (Primary + TimescaleDB)
# ----------------------------------------------------------------------------
# Database host (use container name in Docker Compose, IP/hostname otherwise)
POSTGRES_HOST=localhost

# Database port
POSTGRES_PORT=5432

# Database name
POSTGRES_DB=esp_telemetry

# Database user
POSTGRES_USER=alkhorayef

# Database password (CHANGE THIS IN PRODUCTION!)
POSTGRES_PASSWORD=CHANGE_ME_AlkhorayefESP2025!

# Full database URL (auto-constructed from above, or override)
DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}

# Async database URL for asyncpg
DATABASE_URL_ASYNC=postgresql+asyncpg://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}

# ----------------------------------------------------------------------------
# Database Connection Pool Settings
# ----------------------------------------------------------------------------
# Minimum pool size (connections kept alive)
DB_POOL_MIN_SIZE=10

# Maximum pool size (max concurrent connections)
DB_POOL_MAX_SIZE=20

# Connection pool timeout in seconds
DB_POOL_TIMEOUT=30

# Maximum connection lifetime in seconds (0 = unlimited)
DB_MAX_CONNECTION_AGE=3600

# Query timeout in seconds
DB_QUERY_TIMEOUT=30

# ----------------------------------------------------------------------------
# Redis Configuration (Caching & Real-time)
# ----------------------------------------------------------------------------
# Redis host
REDIS_HOST=localhost

# Redis port
REDIS_PORT=6379

# Redis database number (0-15)
REDIS_DB=0

# Redis password (CHANGE THIS IN PRODUCTION!)
REDIS_PASSWORD=CHANGE_ME_RedisAlkhorayef2025!

# Full Redis URL
REDIS_URL=redis://:${REDIS_PASSWORD}@${REDIS_HOST}:${REDIS_PORT}/${REDIS_DB}

# Redis connection pool size
REDIS_MAX_CONNECTIONS=50

# Cache TTL in seconds (default 5 minutes)
REDIS_DEFAULT_TTL=300

# ----------------------------------------------------------------------------
# RabbitMQ Configuration (Message Queue)
# ----------------------------------------------------------------------------
# RabbitMQ host
RABBITMQ_HOST=localhost

# RabbitMQ port
RABBITMQ_PORT=5672

# RabbitMQ user
RABBITMQ_USER=alkhorayef

# RabbitMQ password (CHANGE THIS IN PRODUCTION!)
RABBITMQ_PASSWORD=CHANGE_ME_RabbitAlkhorayef2025!

# RabbitMQ virtual host
RABBITMQ_VHOST=/

# Full RabbitMQ URL
RABBITMQ_URL=amqp://${RABBITMQ_USER}:${RABBITMQ_PASSWORD}@${RABBITMQ_HOST}:${RABBITMQ_PORT}/${RABBITMQ_VHOST}

# ----------------------------------------------------------------------------
# Neo4j Graph Database (Knowledge Graph)
# ----------------------------------------------------------------------------
# Neo4j URI (bolt protocol)
NEO4J_URI=bolt://localhost:7687

# Neo4j username
NEO4J_USER=neo4j

# Neo4j password (CHANGE THIS IN PRODUCTION!)
NEO4J_PASSWORD=CHANGE_ME_Neo4jAlkhorayef2025!

# Neo4j database name
NEO4J_DATABASE=neo4j

# ----------------------------------------------------------------------------
# Grafana Configuration (Monitoring Dashboards)
# ----------------------------------------------------------------------------
# Grafana admin password (CHANGE THIS IN PRODUCTION!)
GRAFANA_PASSWORD=CHANGE_ME_GrafanaAlkhorayef2025!

# Grafana port
GRAFANA_PORT=3000

# Grafana root URL (for external access)
GRAFANA_ROOT_URL=http://localhost:3000

# ----------------------------------------------------------------------------
# Security & Authentication
# ----------------------------------------------------------------------------
# JWT secret key for token signing (GENERATE A NEW RANDOM KEY!)
# Generate with: python -c "import secrets; print(secrets.token_urlsafe(32))"
JWT_SECRET_KEY=CHANGE_ME_GENERATE_RANDOM_KEY

# JWT algorithm (HS256, RS256, etc.)
JWT_ALGORITHM=HS256

# Access token expiration time in minutes
ACCESS_TOKEN_EXPIRE_MINUTES=30

# Refresh token expiration time in days
REFRESH_TOKEN_EXPIRE_DAYS=7

# CORS allowed origins (comma-separated, * for all)
CORS_ORIGINS=http://localhost:3000,http://localhost:8000

# CORS allow credentials
CORS_ALLOW_CREDENTIALS=true

# API rate limiting (requests per minute)
RATE_LIMIT_PER_MINUTE=60

# ----------------------------------------------------------------------------
# Machine Learning & AI Configuration
# ----------------------------------------------------------------------------
# Path to ML models directory
ML_MODELS_PATH=/app/ml-models

# Enable Graphiti knowledge graph RAG
GRAPHITI_ENABLED=true

# Hugging Face model cache directory
HF_HOME=/app/.cache/huggingface

# PyTorch device (cpu, cuda, mps)
TORCH_DEVICE=cpu

# Number of threads for ML inference
TORCH_NUM_THREADS=4

# Embedding model name
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# LLM model for RAG (if using local models)
LLM_MODEL=gpt-3.5-turbo

# OpenAI API key (if using OpenAI models)
OPENAI_API_KEY=

# ----------------------------------------------------------------------------
# Feature Flags
# ----------------------------------------------------------------------------
# Enable real-time WebSocket telemetry streaming
ENABLE_WEBSOCKET=true

# Enable Prometheus metrics endpoint
ENABLE_METRICS=true

# Enable OpenTelemetry tracing
ENABLE_TRACING=false

# Enable debug mode (DO NOT USE IN PRODUCTION!)
DEBUG_MODE=false

# Enable API documentation (Swagger/ReDoc)
ENABLE_API_DOCS=true

# Enable background task processing
ENABLE_BACKGROUND_TASKS=true

# ----------------------------------------------------------------------------
# Data Retention Policies
# ----------------------------------------------------------------------------
# IoT telemetry data retention in days (Azure backup: 30 days)
# NOTE: Backup system should have all historical data
TELEMETRY_RETENTION_DAYS=30

# Diagnostic results retention in days
DIAGNOSTICS_RETENTION_DAYS=90

# Logs retention in days
LOGS_RETENTION_DAYS=30

# Metrics retention in days
METRICS_RETENTION_DAYS=90

# ----------------------------------------------------------------------------
# Backup Configuration
# ----------------------------------------------------------------------------
# Enable automated backups
ENABLE_AUTOMATED_BACKUP=true

# Backup schedule (cron format: "0 2 * * *" = daily at 2 AM)
BACKUP_SCHEDULE=0 2 * * *

# Backup retention in days
BACKUP_RETENTION_DAYS=90

# Azure Storage account for backups
AZURE_STORAGE_ACCOUNT=

# Azure Storage container
AZURE_STORAGE_CONTAINER=esp-backups

# Azure Storage access key
AZURE_STORAGE_KEY=

# ----------------------------------------------------------------------------
# Monitoring & Alerting
# ----------------------------------------------------------------------------
# Prometheus pushgateway URL (if using)
PROMETHEUS_PUSHGATEWAY_URL=

# Alert email recipients (comma-separated)
ALERT_EMAIL_RECIPIENTS=admin@alkhorayef.com

# SMTP server for email alerts
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USER=
SMTP_PASSWORD=
SMTP_FROM=noreply@alkhorayef.com

# Slack webhook URL for alerts
SLACK_WEBHOOK_URL=

# ----------------------------------------------------------------------------
# Tailscale VPN (Optional)
# ----------------------------------------------------------------------------
# Tailscale authentication key
TAILSCALE_AUTHKEY=

# Tailscale hostname
TAILSCALE_HOSTNAME=alkhorayef-esp

# Enable Tailscale HTTPS
TAILSCALE_HTTPS=true

# ----------------------------------------------------------------------------
# Performance Tuning
# ----------------------------------------------------------------------------
# Maximum request body size in bytes (10 MB)
MAX_REQUEST_SIZE=10485760

# Request timeout in seconds
REQUEST_TIMEOUT=60

# WebSocket ping interval in seconds
WEBSOCKET_PING_INTERVAL=30

# WebSocket ping timeout in seconds
WEBSOCKET_PING_TIMEOUT=10

# Background task queue size
TASK_QUEUE_SIZE=1000

# Maximum concurrent background tasks
MAX_CONCURRENT_TASKS=10

# ----------------------------------------------------------------------------
# Development Settings (ignore in production)
# ----------------------------------------------------------------------------
# Auto-reload on code changes (development only)
AUTO_RELOAD=false

# Detailed error pages (development only)
SHOW_ERROR_DETAILS=false

# SQL query logging (development only)
SQL_ECHO=false
